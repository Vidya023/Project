{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vidya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras import Model, Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv') \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n",
      "(284807,)\n"
     ]
    }
   ],
   "source": [
    "# Target = data['Class'] ==> Last Column\n",
    "# 0 = Normal, 1 = Anomaly \n",
    "\n",
    "X = data.drop(columns=['Class'],axis=1) \n",
    "y = data['Class'] \n",
    "\n",
    "print(X.shape)  \n",
    "print(y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, this is a case of novelty detection, we use only normal data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = y_train[y_train == 0].index \n",
    "train_data = x_train.loc[train_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data using MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "# x_train_scaled = min_max_scaler.fit_transform(train_data.copy())\n",
    "# x_test_scaled = min_max_scaler.transform(x_test.copy()) \n",
    "\n",
    "x_train_scaled = x_train \n",
    "x_test_scaled = x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Autoencoder Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an Autoencoder model using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, output_units, code_size=8):\n",
    "        super().__init__() \n",
    "        self.encoder = Sequential([\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(code_size, activation='relu')\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            Dense(16, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(output_units, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self,inputs):\n",
    "        encoded = self.encoder(inputs) \n",
    "        decoded = self.decoder(encoded) \n",
    "        return decoded     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vidya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vidya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\vidya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vidya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "446/446 [==============================] - 3s 4ms/step - loss: 4.1932 - mse: 375273440.0000 - val_loss: 4.1725 - val_mse: 373017216.0000\n",
      "Epoch 2/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1758 - mse: 375273248.0000 - val_loss: 4.1720 - val_mse: 373017216.0000\n",
      "Epoch 3/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1754 - mse: 375273216.0000 - val_loss: 4.1720 - val_mse: 373017216.0000\n",
      "Epoch 4/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1751 - mse: 375273504.0000 - val_loss: 4.1720 - val_mse: 373017216.0000\n",
      "Epoch 5/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1751 - mse: 375273568.0000 - val_loss: 4.1720 - val_mse: 373017216.0000\n",
      "Epoch 6/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1751 - mse: 375273248.0000 - val_loss: 4.1720 - val_mse: 373017216.0000\n",
      "Epoch 7/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1751 - mse: 375273312.0000 - val_loss: 4.1720 - val_mse: 373017216.0000\n",
      "Epoch 8/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1750 - mse: 375273440.0000 - val_loss: 4.1719 - val_mse: 373017216.0000\n",
      "Epoch 9/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1750 - mse: 375273216.0000 - val_loss: 4.1719 - val_mse: 373017216.0000\n",
      "Epoch 10/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1750 - mse: 375273440.0000 - val_loss: 4.1719 - val_mse: 373017216.0000\n",
      "Epoch 11/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1712 - mse: 375273344.0000 - val_loss: 4.1235 - val_mse: 373017216.0000\n",
      "Epoch 12/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1276 - mse: 375273280.0000 - val_loss: 4.1233 - val_mse: 373017216.0000\n",
      "Epoch 13/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1269 - mse: 375273408.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 14/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1267 - mse: 375273440.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 15/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1266 - mse: 375273216.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 16/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1266 - mse: 375273472.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 17/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1266 - mse: 375273568.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 18/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1265 - mse: 375273504.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 19/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1265 - mse: 375273312.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n",
      "Epoch 20/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1265 - mse: 375273536.0000 - val_loss: 4.1232 - val_mse: 373017216.0000\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(output_units=x_train_scaled.shape[1]) \n",
    "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
    "\n",
    "history = model.fit(x_train_scaled,x_train_scaled,\n",
    "                    epochs=20,batch_size=512,\n",
    "                    validation_data=(x_test_scaled,x_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('MSLE Loss') \n",
    "plt.legend(['loss','val_loss']) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold_method_1(model, x_train_scaled):\n",
    "    reconstructions = model.predict(x_train_scaled)\n",
    "    reconstruction_errors = tf.keras.losses.msle(reconstructions,x_train_scaled)\n",
    "\n",
    "    threshold = np.mean(reconstruction_errors.numpy())+np.std(reconstruction_errors.numpy())\n",
    "    return threshold \n",
    "\n",
    "def find_threshold_method_2(model, x_train_scaled):\n",
    "    reconstructions = model.predict(x_train_scaled) \n",
    "    reconstruction_error = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
    "    threshold2 = np.percentile(reconstruction_error,95)\n",
    "    return threshold2 \n",
    "\n",
    "def get_predictions(model, x_test_scaled, threshold):\n",
    "    predictions = model.predict(x_test_scaled) \n",
    "    errors = tf.keras.losses.msle(predictions,x_test_scaled) \n",
    "    normal_mask = pd.Series(errors)>threshold \n",
    "    preds = normal_mask.map(lambda x: 0.0 if x == True else 1.0)\n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121/7121 [==============================] - 6s 809us/step\n",
      "Threshold from method 1 : 4.731797234789657\n",
      "7121/7121 [==============================] - 6s 811us/step\n",
      "Threshold from method 2 : 4.978731405997491\n"
     ]
    }
   ],
   "source": [
    "threshold = find_threshold_method_1(model,x_train_scaled)\n",
    "print(f\"Threshold from method 1 : {threshold}\") \n",
    "\n",
    "threshold2 = find_threshold_method_2(model,x_train_scaled)\n",
    "print(f\"Threshold from method 2 : {threshold2}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 784us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11649871844387487"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = get_predictions(model, x_test_scaled, threshold)\n",
    "accuracy_score(preds, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "class AutoEncoderTuner(Model):\n",
    "\n",
    "  def __init__(self, hp, output_units, code_size=8):\n",
    "    super().__init__()\n",
    "    dense_1_units = hp.Int('dense_1_units', min_value=16, max_value=72, step=4)\n",
    "    dense_2_units = hp.Int('dense_2_units', min_value=16, max_value=72, step=4)\n",
    "    dense_3_units = hp.Int('dense_3_units', min_value=16, max_value=72, step=4)\n",
    "    dense_4_units = hp.Int('dense_4_units', min_value=16, max_value=72, step=4)\n",
    "    dense_5_units = hp.Int('dense_5_units', min_value=16, max_value=72, step=4)\n",
    "    dense_6_units = hp.Int('dense_6_units', min_value=16, max_value=72, step=4)\n",
    "    \n",
    "    self.encoder = Sequential([\n",
    "      Dense(dense_1_units, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(dense_2_units, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(dense_3_units, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(code_size, activation='relu')\n",
    "    ])\n",
    "    self.decoder = Sequential([\n",
    "      Dense(dense_4_units, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(dense_5_units, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(dense_6_units, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(output_units, activation='sigmoid')\n",
    "    ])\n",
    "  \n",
    "  def call(self, inputs):\n",
    "    encoded = self.encoder(inputs)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "  model = AutoEncoderTuner(hp, 30)\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "  model.compile(\n",
    "      loss='msle',\n",
    "      optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "  )\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 00m 36s]\n",
      "val_loss: 4.169956684112549\n",
      "\n",
      "Best val_loss So Far: 4.123189449310303\n",
      "Total elapsed time: 00h 07m 08s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='autoencoder',\n",
    "    project_name='tuning_autoencoder6'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x_train_scaled, \n",
    "    x_train_scaled, \n",
    "    epochs=20, \n",
    "    batch_size=512,\n",
    "    validation_data=(x_test_scaled, x_test_scaled)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1_units: 16\n",
      "dense_2_units: 60\n",
      "dense_3_units: 56\n",
      "dense_4_units: 20\n",
      "dense_5_units: 56\n",
      "dense_6_units: 20\n",
      "learning_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "hparams = [f'dense_{i}_units' for i in range(1,7)] + ['learning_rate']\n",
    "best_hyperparams = tuner.get_best_hyperparameters()\n",
    "for hps in hparams:\n",
    "  print(f\"{hps}: {best_hyperparams[0][hps]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "446/446 [==============================] - 3s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 2/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 3/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 4/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 5/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 6/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 7/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 8/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 9/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 10/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 11/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 12/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 13/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 14/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 15/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 16/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 17/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 18/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 19/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n",
      "Epoch 20/20\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 4.1264 - val_loss: 4.1232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14a5fb45b10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.compile(loss='msle', optimizer=Adam(0.001))\n",
    "\n",
    "best_model.fit(\n",
    "    x_train_scaled,\n",
    "    x_train_scaled,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_test_scaled, x_test_scaled)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121/7121 [==============================] - 6s 807us/step\n",
      "1781/1781 [==============================] - 2s 841us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11642849619044275"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_ = find_threshold_method_1(best_model, x_train_scaled)\n",
    "preds_ = get_predictions(best_model, x_test_scaled, threshold_)\n",
    "accuracy_score(preds_, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
