{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Machine Learning to Trading Strategies: Using Logistic Regression to Build Momentum-based Trading Strategies - <br>`Patrick Beaudan and Shuoyuan He`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives :\n",
    "\n",
    "    1. Use of ML Model, Logistic Regression, to build a time-series dual momentum trading strategy on the S&P 500 Index\n",
    "    2. Showing how the proposed model outperforms both buy-and-hold and several base-case dual momentum strategies, significantly increasing returns and reducing risk\n",
    "    3. Applying the algorithm to other U.S. and international large capitalization equity indices \n",
    "    4. Analyzing yields improvements in risk-adjusted performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-v0_8-dark-palette')\n",
    "import yfinance as yf \n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tickers \n",
    "1. S&P 500 Index: `^GSPC`\n",
    "2. S&P Small Cap 600 Index (SML): ^SML   \n",
    "3. S&P Mid Cap 400 Index (MID): `^MID`\n",
    "4. FTSE 100 Index (UKX): `^FTSE`\n",
    "5. FTSEurofirst 300 Index (E300): ^FTEU3  \n",
    "6. Tokyo Stock Exchange Price Index (TPX): ^TPX  \n",
    "7. Dow Jones Industrial Average Index (INDU): `^DJI`\n",
    "8. Dow Jones Transportation Average Index (TRAN): `^DJT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = '2018-12-12'\n",
    "\n",
    "# df_sml = yf.download('^SML',start='1993-12-31',end=end) ==> Data not available\n",
    "# df_mid = yf.download('^MID',start='1990-12-31',end=end) \n",
    "# df_mid.to_csv('SPMidCap400.csv')\n",
    "# df_ukx = yf.download('^FTSE',start='1997-12-19',end=end)\n",
    "# df_ukx.to_csv('FTSE100.csv') \n",
    "# df_e300 = yf.download('^FTEU3',start='1985-12-31',end=end) ==> Data not available\n",
    "# df_tpx = yf.download('^TPX',start='1997-12-19',end=end) ==> Data not available\n",
    "# df_dji = yf.download('^DJI',start='1920-01-02',end=end)\n",
    "# df_dji.to_csv('DJIndustry.csv')\n",
    "# df_djt = yf.download('^DJT',start='1920-01-02',end=end) \n",
    "# df_djt.to_csv('DJTransport.csv')\n",
    "# df_sp500 = yf.download('^GSPC',start='1927-12-30',end=end)\n",
    "# df_sp500.to_csv('SP500.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data :  (22844, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-07</th>\n",
       "      <td>2691.260010</td>\n",
       "      <td>2708.540039</td>\n",
       "      <td>2623.139893</td>\n",
       "      <td>2633.080078</td>\n",
       "      <td>2633.080078</td>\n",
       "      <td>4242240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-10</th>\n",
       "      <td>2630.860107</td>\n",
       "      <td>2647.510010</td>\n",
       "      <td>2583.229980</td>\n",
       "      <td>2637.719971</td>\n",
       "      <td>2637.719971</td>\n",
       "      <td>4162880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11</th>\n",
       "      <td>2664.439941</td>\n",
       "      <td>2674.350098</td>\n",
       "      <td>2621.300049</td>\n",
       "      <td>2636.780029</td>\n",
       "      <td>2636.780029</td>\n",
       "      <td>3963440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2018-12-07  2691.260010  2708.540039  2623.139893  2633.080078  2633.080078   \n",
       "2018-12-10  2630.860107  2647.510010  2583.229980  2637.719971  2637.719971   \n",
       "2018-12-11  2664.439941  2674.350098  2621.300049  2636.780029  2636.780029   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2018-12-07  4242240000  \n",
       "2018-12-10  4162880000  \n",
       "2018-12-11  3963440000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mid = pd.read_csv('SPMidCap400.csv')\n",
    "df_mid.set_index('Date', inplace=True)\n",
    "\n",
    "df_ukx = pd.read_csv('FTSE100.csv')\n",
    "df_ukx.set_index('Date', inplace=True) \n",
    "\n",
    "df_dji = pd.read_csv('DJIndustry.csv')\n",
    "df_dji.set_index('Date', inplace=True)\n",
    "\n",
    "df_djt = pd.read_csv('DJTransport.csv') \n",
    "df_djt.set_index('Date', inplace=True) \n",
    "\n",
    "data = pd.read_csv('SP500.csv')\n",
    "data.set_index('Date',inplace=True) \n",
    "\n",
    "df_21 = data.copy() \n",
    "\n",
    "print('Shape of data : ',data.shape) \n",
    "data.tail(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining class to include base-features Momentum and Drawdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Momentum features are calculated over time frames of 30, 60, 90, 120, 180, 270, 300, 360 days\n",
    "* Drawdown features are calculated over time frames of 15, 60, 90, 120 days\n",
    "\n",
    "Also, it is instructed to calculate features by skipping last month. We follow the convention of 252 business days per calendar year and 21 business days per calendar month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are selected based on the fact that observing the change in the shape of the price history using multiple historical time windows for momenta and drawdowns is more pertinent than considering other metrics to predict short-term profitability. So, we use momenta and drawdowns of different timeframes as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncludeFeatures:\n",
    "    def __init__(self,data):\n",
    "        self.data = data \n",
    "\n",
    "    def calculate_momentum(self,window): # computing the rate of change in the stock's closing price over window days\n",
    "        self.data[f'momntm_{window}'] =  self.data['Adj Close'] - self.data['Adj Close'].shift(window) \n",
    "\n",
    "    def calculate_drawdown(self,window): # Compute the drawdown by finding the peak and trough in the price data\n",
    "        # calculating cumulative maximum for stocks price\n",
    "        self.data['Cumulative_Peak'] = self.data['Adj Close'].cummax() # max of cumulative value upto that day\n",
    "        # calculating drawdown \n",
    "        self.data[f'drwdwn_{window}'] = (self.data['Adj Close']-self.data['Cumulative_Peak'])/self.data['Cumulative_Peak']\n",
    "\n",
    "    def include_features(self):\n",
    "        \n",
    "        momentum_windows = [30, 60, 90, 120, 180, 270, 300, 360]\n",
    "        drawdwn_windows = [15, 60, 90, 120]    \n",
    "\n",
    "        for days in momentum_windows:\n",
    "            self.calculate_momentum(days) \n",
    "\n",
    "        for days in drawdwn_windows:\n",
    "            self.calculate_drawdown(days) \n",
    "        \n",
    "        self.data.drop(columns=['Cumulative_Peak','Open','High','Low','Close','Volume'],axis=1,inplace=True)\n",
    "        return self.data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22484, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>momntm_30</th>\n",
       "      <th>momntm_60</th>\n",
       "      <th>momntm_90</th>\n",
       "      <th>momntm_120</th>\n",
       "      <th>momntm_180</th>\n",
       "      <th>momntm_270</th>\n",
       "      <th>momntm_300</th>\n",
       "      <th>momntm_360</th>\n",
       "      <th>drwdwn_15</th>\n",
       "      <th>drwdwn_60</th>\n",
       "      <th>drwdwn_90</th>\n",
       "      <th>drwdwn_120</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1929-06-10</th>\n",
       "      <td>25.270000</td>\n",
       "      <td>-0.309999</td>\n",
       "      <td>-0.459999</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>2.74</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>5.060001</td>\n",
       "      <td>6.380001</td>\n",
       "      <td>7.610001</td>\n",
       "      <td>-0.041714</td>\n",
       "      <td>-0.041714</td>\n",
       "      <td>-0.041714</td>\n",
       "      <td>-0.041714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-06-11</th>\n",
       "      <td>25.430000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.650000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>2.99</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.070000</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>-0.035647</td>\n",
       "      <td>-0.035647</td>\n",
       "      <td>-0.035647</td>\n",
       "      <td>-0.035647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-06-12</th>\n",
       "      <td>25.450001</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.289999</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.230001</td>\n",
       "      <td>5.010000</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>7.730001</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>-0.034888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close  momntm_30  momntm_60  momntm_90  momntm_120  \\\n",
       "Date                                                                 \n",
       "1929-06-10  25.270000  -0.309999  -0.459999  -0.090000        2.74   \n",
       "1929-06-11  25.430000  -0.100000  -0.650000  -0.020000        2.99   \n",
       "1929-06-12  25.450001  -0.490000  -0.590000  -0.289999        2.75   \n",
       "\n",
       "            momntm_180  momntm_270  momntm_300  momntm_360  drwdwn_15  \\\n",
       "Date                                                                    \n",
       "1929-06-10    4.090000    5.060001    6.380001    7.610001  -0.041714   \n",
       "1929-06-11    4.250000    5.070000    6.480000    7.670000  -0.035647   \n",
       "1929-06-12    4.230001    5.010000    6.170000    7.730001  -0.034888   \n",
       "\n",
       "            drwdwn_60  drwdwn_90  drwdwn_120  \n",
       "Date                                          \n",
       "1929-06-10  -0.041714  -0.041714   -0.041714  \n",
       "1929-06-11  -0.035647  -0.035647   -0.035647  \n",
       "1929-06-12  -0.034888  -0.034888   -0.034888  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_feat = IncludeFeatures(data) \n",
    "data_feat = include_feat.include_features()\n",
    "data_feat.dropna(inplace=True)\n",
    "print(data_feat.shape) \n",
    "data_feat.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Null values : {data_feat.isna().sum().sum()}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyzing Key Performance Indicators over sample indices over the entire period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KPIs analysed here are Annual Return, Sharpe Ratio, Volatility, Maximum Drawdown, Average Daily Drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPIs:\n",
    "    def __init__(self,data):\n",
    "        self.datac = data  \n",
    "\n",
    "    def annual_return(self,datac):\n",
    "        cumulative_returns = (1+datac['Daily_Return']).prod()-1 \n",
    "        n_days = datac.shape[0]     # Number of trading days \n",
    "        annualized_return = (1+cumulative_returns)**(252/n_days)-1\n",
    "        return annualized_return \n",
    "    \n",
    "    def sharpe_ratio(self,datac):\n",
    "        average_return = datac['Daily_Return'].mean() \n",
    "        risk_free_rate = 0.01/252  # constant 1% annual risk-free rate\n",
    "        std_dev = datac['Daily_Return'].std() \n",
    "        sharpe_ratio = (average_return-risk_free_rate)*10/std_dev\n",
    "        return sharpe_ratio \n",
    "\n",
    "    def volatility(self,datac):\n",
    "        daily_volatility = datac['Daily_Return'].std()\n",
    "        trading_days_per_year = 252 \n",
    "        annual_volatility = daily_volatility*np.sqrt(trading_days_per_year)   # Annualizing Volatility\n",
    "        return annual_volatility \n",
    "    \n",
    "    def max_drawdown(self,datac):\n",
    "        datac['Running_max'] = datac['Adj Close'].cummax() \n",
    "        datac['Drawdowns'] = (datac['Adj Close']-datac['Running_max'])/datac['Running_max']\n",
    "\n",
    "        max_drawdown = datac['Drawdowns'].min() \n",
    "        avg_drawdown = datac['Drawdowns'].mean() \n",
    "\n",
    "        return max_drawdown, avg_drawdown \n",
    "\n",
    "    def calculate_kpi(self):        \n",
    "        self.datac['Log_Return'] =  np.log(self.datac['Adj Close']/self.datac['Adj Close'].shift(1))\n",
    "        self.datac['Daily_Return'] = self.datac['Adj Close'].pct_change() \n",
    "        self.datac.dropna(inplace=True) \n",
    "\n",
    "        annualized_return = self.annual_return(self.datac)\n",
    "        sharpe_ratio = self.sharpe_ratio(self.datac)\n",
    "        annual_volatility = self.volatility(self.datac)\n",
    "        max_drawdown, avg_drawdown = self.max_drawdown(self.datac)\n",
    "\n",
    "        print(f'Annual Return : {annualized_return*100:.1f}%')\n",
    "        print(f'Sharpe Ratio : {sharpe_ratio:.2f}')\n",
    "        print(f'Volatility : {annual_volatility*100:.0f}%')\n",
    "        print(f'Maximum Drawdown : {max_drawdown*100:.0f}%')\n",
    "        print(f'Average Daily Drawdown : {avg_drawdown*100:.0f}%') \n",
    "\n",
    "        self.datac.drop(columns=['Log_Return','Daily_Return','Running_max','Drawdowns'],axis=1,inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Performace Metrics of S&P 500 ====================\n",
      "\n",
      "Annual Return : 5.3%\n",
      "Sharpe Ratio : 0.20\n",
      "Volatility : 19%\n",
      "Maximum Drawdown : -86%\n",
      "Average Daily Drawdown : -22%\n",
      "\n",
      "==================== Performace Metrics of S&P Mid Cap ====================\n",
      "\n",
      "Annual Return : 10.8%\n",
      "Sharpe Ratio : 0.37\n",
      "Volatility : 19%\n",
      "Maximum Drawdown : -56%\n",
      "Average Daily Drawdown : -7%\n",
      "\n",
      "==================== Performace Metrics of FTSE 100 ====================\n",
      "\n",
      "Annual Return : 1.5%\n",
      "Sharpe Ratio : 0.07\n",
      "Volatility : 19%\n",
      "Maximum Drawdown : -53%\n",
      "Average Daily Drawdown : -16%\n",
      "\n",
      "==================== Performace Metrics of DJ Industry ====================\n",
      "\n",
      "Annual Return : 7.9%\n",
      "Sharpe Ratio : 0.30\n",
      "Volatility : 17%\n",
      "Maximum Drawdown : -54%\n",
      "Average Daily Drawdown : -9%\n",
      "\n",
      "==================== Performace Metrics of DJ Transport ====================\n",
      "\n",
      "Annual Return : 7.7%\n",
      "Sharpe Ratio : 0.25\n",
      "Volatility : 23%\n",
      "Maximum Drawdown : -61%\n",
      "Average Daily Drawdown : -13%\n"
     ]
    }
   ],
   "source": [
    "calc_indices = {'S&P 500':data, 'S&P Mid Cap':df_mid, 'FTSE 100':df_ukx, 'DJ Industry':df_dji, \n",
    "                'DJ Transport':df_djt}\n",
    "\n",
    "for ind,df in calc_indices.items():\n",
    "    print() \n",
    "    print('='*20,f'Performace Metrics of {ind}','='*20)\n",
    "    print() \n",
    "    calc_kpi = KPIs(df)\n",
    "    calc_kpi.calculate_kpi()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Buy and Hold Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trading every day for last one year. Compute returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "databnh = data.copy()\n",
    "databnh['Momentum'] = (databnh['Adj Close'].pct_change(periods=252)*100).round(2)  # 252 days \n",
    "databnh.dropna(inplace=True)\n",
    "databnh = databnh.iloc[-252:]  # Selecting Values for last one year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "databnh = databnh[['Adj Close','Momentum']]\n",
    "databnh['Signal'] = 0\n",
    "\n",
    "for i in range(len(databnh)):\n",
    "    if databnh['Momentum'].iloc[i] >= 5:\n",
    "        databnh.loc[databnh.index[i], 'Signal'] = 1\n",
    "    else:\n",
    "        databnh.loc[databnh.index[i], 'Signal'] = -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before :  (252, 3)\n",
      "Shape after :  (233, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before : ', databnh.shape)\n",
    "databnh_1 = databnh[databnh['Signal']==1]  \n",
    "print('Shape after : ', databnh_1.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>2659.989990</td>\n",
       "      <td>17.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>2664.110107</td>\n",
       "      <td>18.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>2662.850098</td>\n",
       "      <td>17.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>2652.010010</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>2675.810059</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Adj Close  Momentum  Signal\n",
       "Date                                     \n",
       "2017-12-11  2659.989990     17.72       1\n",
       "2017-12-12  2664.110107     18.04       1\n",
       "2017-12-13  2662.850098     17.22       1\n",
       "2017-12-14  2652.010010     17.70       1\n",
       "2017-12-15  2675.810059     18.29       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databnh_1.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Statistics of SPX for one year ====================\n",
      "\n",
      "Annual Return : -0.9%\n",
      "Sharpe Ratio : -0.03\n",
      "Volatility : 16%\n",
      "Maximum Drawdown : -10%\n",
      "Average Daily Drawdown : -4%\n",
      "==================== Statistics for Buy and Hold for one year revisiting signal every day ====================\n",
      "\n",
      "Annual Return : 5.3%\n",
      "Sharpe Ratio : 0.23\n",
      "Volatility : 14%\n",
      "Maximum Drawdown : -10%\n",
      "Average Daily Drawdown : -4%\n"
     ]
    }
   ],
   "source": [
    "print('='*20,'Statistics of SPX for one year','='*20) \n",
    "print() \n",
    "calc_kpi = KPIs(databnh)\n",
    "calc_kpi.calculate_kpi()  \n",
    "print('='*20,'Statistics for Buy and Hold for one year revisiting signal every day','='*20) \n",
    "print() \n",
    "calc_kpi = KPIs(databnh_1)\n",
    "calc_kpi.calculate_kpi()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Classical Time Series Dual-Momentum Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy\n",
    "\n",
    "1. The momentum, i.e. the percentage price change of a security, is calculated over a historical time horizon of twelve months, skipping the most recent month \n",
    "2. If momentum > threshold (here,5%=0.05) => Invest \n",
    "3. If momentum < threshold => the portfolio is moved to cash in the long-only strategy, or moved to a short position in the long-short strategy \n",
    "4. This investment decision is revisited at regular intervals of one month "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating momentum, percentage change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Momentum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1929-01-03</th>\n",
       "      <td>40.770107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-01-04</th>\n",
       "      <td>39.921172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-01-07</th>\n",
       "      <td>36.851021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Momentum\n",
       "Date                 \n",
       "1929-01-03  40.770107\n",
       "1929-01-04  39.921172\n",
       "1929-01-07  36.851021"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_days_per_month = 21\n",
    "no_of_months = 12  \n",
    "time_horizon = trading_days_per_month*no_of_months # 252 days \n",
    "\n",
    "df_21['Momentum'] = df_21['Adj Close'].pct_change(periods=252)*100\n",
    "df_21.dropna(inplace=True)\n",
    "df_21.drop(columns=['Open','High','Low','Close','Volume', 'Adj Close'],axis=1,inplace=True)\n",
    "\n",
    "df_21.head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signals are generated every 21 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1929-01-03</th>\n",
       "      <td>40.770107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-01-04</th>\n",
       "      <td>39.921172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-01-07</th>\n",
       "      <td>36.851021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-01-08</th>\n",
       "      <td>37.720804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-01-09</th>\n",
       "      <td>38.958104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Momentum  Signal\n",
       "Date                         \n",
       "1929-01-03  40.770107       0\n",
       "1929-01-04  39.921172       1\n",
       "1929-01-07  36.851021       1\n",
       "1929-01-08  37.720804       1\n",
       "1929-01-09  38.958104       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_signals(df_g, interval, threshold = 5):\n",
    "    df_g['Signal'] = 0\n",
    "\n",
    "    for i in range(interval, len(df_g), interval):\n",
    "        if df_g['Momentum'].iloc[i] >= threshold:\n",
    "            df_g['Signal'].iloc[i] = 1  # Invest\n",
    "        else:\n",
    "            df_g['Signal'].iloc[i] = -1 # Move to cash or short position\n",
    "\n",
    "    return df_g \n",
    "\n",
    "df_21 = generate_signals(df_21, 1, 5) \n",
    "df_21.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_21)\n",
    "# Slice the DataFrame to exclude the last 21 rows for skipping most recent month \n",
    "df_x = df_21.copy() \n",
    "df_21 = df_x.iloc[:n-252] \n",
    "df_1yr = df_x.iloc[-252:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22340, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_21.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1yr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_21 = df_21[df_21['Signal']!=0] \n",
    "df_1yr = df_1yr[df_1yr['Signal']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal\n",
      " 1    13176\n",
      "-1     9163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_21['Signal'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal\n",
      " 1    233\n",
      "-1     19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_1yr['Signal'].value_counts())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining Function to create polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(data,degree): \n",
    "\n",
    "    feature_names = data.columns \n",
    "    # feature_names = ['Adj Close', 'momntm_30', 'momntm_60', 'momntm_90', 'momntm_120',\n",
    "    #                  'momntm_180', 'momntm_270', 'momntm_300', 'momntm_360', 'drwdwn_15',\n",
    "    #                  'drwdwn_60', 'drwdwn_90', 'drwdwn_120'] \n",
    "    \n",
    "    if data.shape[1] != len(feature_names):\n",
    "        raise ValueError(\"The number of features in the data does not match the length of feature names.\")\n",
    "\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_feat = poly.fit_transform(data) \n",
    "    \n",
    "    feature_names_poly = poly.get_feature_names_out(input_features=feature_names)\n",
    "    \n",
    "    df_poly = pd.DataFrame(poly_feat, columns=feature_names_poly, index=data.index) \n",
    "    print(f'Shape of df_poly of degree 1 : ',data.shape) \n",
    "    print(f'Shape of df_poly of degree {degree} : ',df_poly.shape) \n",
    "    print('Number of duplicate columns : ',len(df_poly.columns)-len(set(df_poly.columns))) \n",
    "    return df_poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_poly of degree 1 :  (22483, 13)\n",
      "Shape of df_poly of degree 2 :  (22483, 104)\n",
      "Number of duplicate columns :  0\n"
     ]
    }
   ],
   "source": [
    "x_quad = degree(data_feat,2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_poly of degree 1 :  (22483, 13)\n",
      "Shape of df_poly of degree 3 :  (22483, 559)\n",
      "Number of duplicate columns :  0\n"
     ]
    }
   ],
   "source": [
    "x_cubic = degree(data_feat,3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating Datasets for training with Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Linear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of linear dataset before concatenation :  (22483, 13)\n",
      "Shape of linear dataset after concatenation :  (22231, 15)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of linear dataset before concatenation : ',data_feat.shape)\n",
    "x_linear = df_21.join(data_feat) \n",
    "x_linear.dropna(inplace=True)  \n",
    "print('Shape of linear dataset after concatenation : ',x_linear.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of linear dataset before concatenation :  (22483, 13)\n",
      "Shape of linear dataset after concatenation :  (252, 15)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of linear dataset before concatenation : ',data_feat.shape)\n",
    "xp_linear = df_1yr.join(data_feat) \n",
    "xp_linear.dropna(inplace=True)  \n",
    "print('Shape of linear dataset after concatenation : ',xp_linear.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Quadratic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of quadratic dataset before concatenation :  (22483, 104)\n",
      "Shape of quadratic dataset after concatenation :  (22231, 106)\n"
     ]
    }
   ],
   "source": [
    "xp_quad =  x_quad.copy() \n",
    "print('Shape of quadratic dataset before concatenation : ',x_quad.shape)\n",
    "x_quad = df_21.join(x_quad) \n",
    "x_quad.dropna(inplace=True) \n",
    "print('Shape of quadratic dataset after concatenation : ',x_quad.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of quadratic dataset before concatenation :  (22483, 104)\n",
      "Shape of quadratic dataset after concatenation :  (252, 106)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of quadratic dataset before concatenation : ',xp_quad.shape)\n",
    "xp_quad = df_1yr.join(xp_quad) \n",
    "xp_quad.dropna(inplace=True) \n",
    "print('Shape of quadratic dataset after concatenation : ',xp_quad.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Cubic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cubic dataset before concatenation :  (22483, 559)\n",
      "Shape of cubic dataset after concatenation :  (22231, 561)\n"
     ]
    }
   ],
   "source": [
    "xp_cubic = x_cubic.copy() \n",
    "print('Shape of cubic dataset before concatenation : ',x_cubic.shape)\n",
    "x_cubic = df_21.join(x_cubic) \n",
    "x_cubic.dropna(inplace=True) \n",
    "print('Shape of cubic dataset after concatenation : ',x_cubic.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of quadratic dataset before concatenation :  (22483, 559)\n",
      "Shape of quadratic dataset after concatenation :  (252, 561)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of quadratic dataset before concatenation : ',xp_cubic.shape)\n",
    "xp_cubic = df_1yr.join(xp_cubic) \n",
    "xp_cubic.dropna(inplace=True) \n",
    "print('Shape of quadratic dataset after concatenation : ',xp_cubic.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Class for Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model metrics calculated are cost function, accuracy, confusion matrix and classification report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the cost function, also known as the loss function, for logistic regression, we need to use the logistic loss function, which is commonly referred to as cross-entropy loss or log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self):\n",
    "        self.train_size = 0.4\n",
    "        self.random_state = 42 \n",
    "\n",
    "    def scaling_x(self,X):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_X = scaler.fit_transform(X)\n",
    "        return scaled_X\n",
    "    \n",
    "    def cost_func(self,model,x_test,y_test): \n",
    "        probabilities = model.predict_proba(x_test)[:,1] # Getting probabilities for class 1 (positive class)\n",
    "        cost = log_loss(y_test,probabilities) \n",
    "        return cost \n",
    "\n",
    "    def model_metrics(self,model,x_test,y_test):\n",
    "        y_pred = model.predict(x_test) \n",
    "        cost_fn = self.cost_func(model,x_test,y_test)\n",
    "        accuracy = accuracy_score(y_test,y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "        print(f'Cost function : {cost_fn:.2f}') \n",
    "        print(f'Accuracy : {accuracy:.2f}')\n",
    "        print('Confusion Matrix : ')\n",
    "        print(conf_matrix) \n",
    "        print('Classification Report : ')\n",
    "        print(class_report) \n",
    "    \n",
    "    def training_model(self,df,df_exp):\n",
    "\n",
    "        X = df.drop(columns=['Signal'],axis=1)\n",
    "        Y = df['Signal']  \n",
    "\n",
    "        scaled_X = self.scaling_x(X)\n",
    "        # Split the data into initial training set (40%) and test set (60%)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(scaled_X,Y,train_size=0.4, shuffle=False, \n",
    "                                                            random_state=42)\n",
    "        model = LogisticRegression(C=1.0)   # C is the regularization parameter\n",
    "        \n",
    "        model.fit(x_train,y_train) \n",
    "\n",
    "        print('='*20,'Metrics for Train set','='*20)\n",
    "        print()    \n",
    "        self.model_metrics(model,x_train,y_train) \n",
    "        print('='*20,'Metrics for Test set','='*20)\n",
    "        print()    \n",
    "        self.model_metrics(model,x_test,y_test) \n",
    "        print() \n",
    "\n",
    "        df_exp = df_exp.drop(columns=['Signal'],axis=1)\n",
    "        y_pred = model.predict(df_exp) \n",
    "        return y_pred \n",
    "        \n",
    "logistic = logistic_regression()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluation of Linear, Quadratic and Cubic Combination of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 Evaluation on Linear Combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Metrics for Train set ====================\n",
      "\n",
      "Cost function : 0.03\n",
      "Accuracy : 1.00\n",
      "Confusion Matrix : \n",
      "[[4246    0]\n",
      " [  26 4620]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      4246\n",
      "           1       1.00      0.99      1.00      4646\n",
      "\n",
      "    accuracy                           1.00      8892\n",
      "   macro avg       1.00      1.00      1.00      8892\n",
      "weighted avg       1.00      1.00      1.00      8892\n",
      "\n",
      "==================== Metrics for Test set ====================\n",
      "\n",
      "Cost function : 0.06\n",
      "Accuracy : 0.98\n",
      "Confusion Matrix : \n",
      "[[4908    9]\n",
      " [ 226 8196]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      1.00      0.98      4917\n",
      "           1       1.00      0.97      0.99      8422\n",
      "\n",
      "    accuracy                           0.98     13339\n",
      "   macro avg       0.98      0.99      0.98     13339\n",
      "weighted avg       0.98      0.98      0.98     13339\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yl_pred = logistic.training_model(x_linear,xp_linear)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>17.723153</td>\n",
       "      <td>1</td>\n",
       "      <td>2659.989990</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>18.039759</td>\n",
       "      <td>1</td>\n",
       "      <td>2664.110107</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>17.217357</td>\n",
       "      <td>1</td>\n",
       "      <td>2662.850098</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>17.695536</td>\n",
       "      <td>1</td>\n",
       "      <td>2652.010010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>18.292420</td>\n",
       "      <td>1</td>\n",
       "      <td>2675.810059</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-04</th>\n",
       "      <td>2.296704</td>\n",
       "      <td>-1</td>\n",
       "      <td>2700.060059</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-06</th>\n",
       "      <td>2.524363</td>\n",
       "      <td>-1</td>\n",
       "      <td>2695.949951</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-07</th>\n",
       "      <td>0.144909</td>\n",
       "      <td>-1</td>\n",
       "      <td>2633.080078</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-10</th>\n",
       "      <td>0.028062</td>\n",
       "      <td>-1</td>\n",
       "      <td>2637.719971</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11</th>\n",
       "      <td>-0.555156</td>\n",
       "      <td>-1</td>\n",
       "      <td>2636.780029</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Momentum  Signal    Adj Close  Predicted\n",
       "Date                                                 \n",
       "2017-12-11  17.723153       1  2659.989990         -1\n",
       "2017-12-12  18.039759       1  2664.110107         -1\n",
       "2017-12-13  17.217357       1  2662.850098         -1\n",
       "2017-12-14  17.695536       1  2652.010010         -1\n",
       "2017-12-15  18.292420       1  2675.810059         -1\n",
       "...               ...     ...          ...        ...\n",
       "2018-12-04   2.296704      -1  2700.060059         -1\n",
       "2018-12-06   2.524363      -1  2695.949951         -1\n",
       "2018-12-07   0.144909      -1  2633.080078         -1\n",
       "2018-12-10   0.028062      -1  2637.719971         -1\n",
       "2018-12-11  -0.555156      -1  2636.780029         -1\n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp_linear = xp_linear[['Momentum','Signal','Adj Close']] \n",
    "xp_linear['Predicted'] = yl_pred \n",
    "xp_linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Observed values for Signals ====================\n",
      "Signal\n",
      " 1    233\n",
      "-1     19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================== Predicted values for Signals ====================\n",
      "Predicted\n",
      "-1    252\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('='*20,'Observed values for Signals','='*20) \n",
    "print(xp_linear['Signal'].value_counts()) \n",
    "print() \n",
    "print('='*20,'Predicted values for Signals','='*20) \n",
    "print(xp_linear['Predicted'].value_counts())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 Evaluation on Quadratic Combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Metrics for Train set ====================\n",
      "\n",
      "Cost function : 0.03\n",
      "Accuracy : 1.00\n",
      "Confusion Matrix : \n",
      "[[4233   13]\n",
      " [  29 4617]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      4246\n",
      "           1       1.00      0.99      1.00      4646\n",
      "\n",
      "    accuracy                           1.00      8892\n",
      "   macro avg       1.00      1.00      1.00      8892\n",
      "weighted avg       1.00      1.00      1.00      8892\n",
      "\n",
      "==================== Metrics for Test set ====================\n",
      "\n",
      "Cost function : 0.13\n",
      "Accuracy : 0.97\n",
      "Confusion Matrix : \n",
      "[[4669  248]\n",
      " [ 108 8314]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.95      0.96      4917\n",
      "           1       0.97      0.99      0.98      8422\n",
      "\n",
      "    accuracy                           0.97     13339\n",
      "   macro avg       0.97      0.97      0.97     13339\n",
      "weighted avg       0.97      0.97      0.97     13339\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yq_pred = logistic.training_model(x_quad,xp_quad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>17.723153</td>\n",
       "      <td>1</td>\n",
       "      <td>2659.989990</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>18.039759</td>\n",
       "      <td>1</td>\n",
       "      <td>2664.110107</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>17.217357</td>\n",
       "      <td>1</td>\n",
       "      <td>2662.850098</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>17.695536</td>\n",
       "      <td>1</td>\n",
       "      <td>2652.010010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>18.292420</td>\n",
       "      <td>1</td>\n",
       "      <td>2675.810059</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-04</th>\n",
       "      <td>2.296704</td>\n",
       "      <td>-1</td>\n",
       "      <td>2700.060059</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-06</th>\n",
       "      <td>2.524363</td>\n",
       "      <td>-1</td>\n",
       "      <td>2695.949951</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-07</th>\n",
       "      <td>0.144909</td>\n",
       "      <td>-1</td>\n",
       "      <td>2633.080078</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-10</th>\n",
       "      <td>0.028062</td>\n",
       "      <td>-1</td>\n",
       "      <td>2637.719971</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11</th>\n",
       "      <td>-0.555156</td>\n",
       "      <td>-1</td>\n",
       "      <td>2636.780029</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Momentum  Signal    Adj Close  Predicted\n",
       "Date                                                 \n",
       "2017-12-11  17.723153       1  2659.989990         -1\n",
       "2017-12-12  18.039759       1  2664.110107         -1\n",
       "2017-12-13  17.217357       1  2662.850098         -1\n",
       "2017-12-14  17.695536       1  2652.010010         -1\n",
       "2017-12-15  18.292420       1  2675.810059         -1\n",
       "...               ...     ...          ...        ...\n",
       "2018-12-04   2.296704      -1  2700.060059         -1\n",
       "2018-12-06   2.524363      -1  2695.949951         -1\n",
       "2018-12-07   0.144909      -1  2633.080078         -1\n",
       "2018-12-10   0.028062      -1  2637.719971         -1\n",
       "2018-12-11  -0.555156      -1  2636.780029         -1\n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp_quad = xp_quad[['Momentum','Signal','Adj Close']] \n",
    "xp_quad['Predicted'] = yq_pred \n",
    "xp_quad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Observed values for Signals ====================\n",
      "Signal\n",
      " 1    233\n",
      "-1     19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================== Predicted values for Signals ====================\n",
      "Predicted\n",
      "-1    252\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('='*20,'Observed values for Signals','='*20) \n",
    "print(xp_quad['Signal'].value_counts()) \n",
    "print() \n",
    "print('='*20,'Predicted values for Signals','='*20) \n",
    "print(xp_quad['Predicted'].value_counts())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 Evaluation on Cubic Combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Metrics for Train set ====================\n",
      "\n",
      "Cost function : 0.03\n",
      "Accuracy : 1.00\n",
      "Confusion Matrix : \n",
      "[[4236   10]\n",
      " [  28 4618]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      4246\n",
      "           1       1.00      0.99      1.00      4646\n",
      "\n",
      "    accuracy                           1.00      8892\n",
      "   macro avg       1.00      1.00      1.00      8892\n",
      "weighted avg       1.00      1.00      1.00      8892\n",
      "\n",
      "==================== Metrics for Test set ====================\n",
      "\n",
      "Cost function : 0.11\n",
      "Accuracy : 0.97\n",
      "Confusion Matrix : \n",
      "[[4629  288]\n",
      " [  81 8341]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.94      0.96      4917\n",
      "           1       0.97      0.99      0.98      8422\n",
      "\n",
      "    accuracy                           0.97     13339\n",
      "   macro avg       0.97      0.97      0.97     13339\n",
      "weighted avg       0.97      0.97      0.97     13339\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yc_pred = logistic.training_model(x_cubic,xp_cubic)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>17.723153</td>\n",
       "      <td>1</td>\n",
       "      <td>2659.989990</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>18.039759</td>\n",
       "      <td>1</td>\n",
       "      <td>2664.110107</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>17.217357</td>\n",
       "      <td>1</td>\n",
       "      <td>2662.850098</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>17.695536</td>\n",
       "      <td>1</td>\n",
       "      <td>2652.010010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>18.292420</td>\n",
       "      <td>1</td>\n",
       "      <td>2675.810059</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-04</th>\n",
       "      <td>2.296704</td>\n",
       "      <td>-1</td>\n",
       "      <td>2700.060059</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-06</th>\n",
       "      <td>2.524363</td>\n",
       "      <td>-1</td>\n",
       "      <td>2695.949951</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-07</th>\n",
       "      <td>0.144909</td>\n",
       "      <td>-1</td>\n",
       "      <td>2633.080078</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-10</th>\n",
       "      <td>0.028062</td>\n",
       "      <td>-1</td>\n",
       "      <td>2637.719971</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11</th>\n",
       "      <td>-0.555156</td>\n",
       "      <td>-1</td>\n",
       "      <td>2636.780029</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Momentum  Signal    Adj Close  Predicted\n",
       "Date                                                 \n",
       "2017-12-11  17.723153       1  2659.989990         -1\n",
       "2017-12-12  18.039759       1  2664.110107         -1\n",
       "2017-12-13  17.217357       1  2662.850098         -1\n",
       "2017-12-14  17.695536       1  2652.010010         -1\n",
       "2017-12-15  18.292420       1  2675.810059         -1\n",
       "...               ...     ...          ...        ...\n",
       "2018-12-04   2.296704      -1  2700.060059         -1\n",
       "2018-12-06   2.524363      -1  2695.949951         -1\n",
       "2018-12-07   0.144909      -1  2633.080078         -1\n",
       "2018-12-10   0.028062      -1  2637.719971         -1\n",
       "2018-12-11  -0.555156      -1  2636.780029         -1\n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp_cubic = xp_cubic[['Momentum','Signal','Adj Close']] \n",
    "xp_cubic['Predicted'] = yc_pred \n",
    "xp_cubic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Observed values for Signals ====================\n",
      "Signal\n",
      " 1    233\n",
      "-1     19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================== Predicted values for Signals ====================\n",
      "Predicted\n",
      "-1    252\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('='*20,'Observed values for Signals','='*20) \n",
    "print(xp_cubic['Signal'].value_counts()) \n",
    "print() \n",
    "print('='*20,'Predicted values for Signals','='*20) \n",
    "print(xp_cubic['Predicted'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Statistics of SPX for one year ====================\n",
      "\n",
      "Annual Return : -1.0%\n",
      "Sharpe Ratio : -0.03\n",
      "Volatility : 16%\n",
      "Maximum Drawdown : -10%\n",
      "Average Daily Drawdown : -4%\n",
      "==================== Statistics for Buy and Hold for one year revisiting signal every day ====================\n",
      "\n",
      "Annual Return : -0.9%\n",
      "Sharpe Ratio : -0.03\n",
      "Volatility : 16%\n",
      "Maximum Drawdown : -10%\n",
      "Average Daily Drawdown : -4%\n"
     ]
    }
   ],
   "source": [
    "print('='*20,'Statistics of SPX for one year','='*20) \n",
    "print() \n",
    "calc_kpi = KPIs(databnh)\n",
    "calc_kpi.calculate_kpi()  \n",
    "print('='*20,'Statistics for Buy and Hold for one year revisiting signal every day','='*20) \n",
    "print() \n",
    "calc_kpi = KPIs(xp_cubic) \n",
    "calc_kpi.calculate_kpi()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Sliding Window over Cubic Polynomials "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training on an initial set of data (40% of data)\n",
    "2. Training calibrate parameters before applying to testing sets\n",
    "3. Convergence is monitored by cost function.\n",
    "4. Convergence is achieved when (cost function < threshold) => Threshold=0.01\n",
    "5. Convergence is checked every 50 days \n",
    "6. Window is slid forward after convergence is achieved \n",
    "7. Retraining is done every 8 years\n",
    "8. Continue this till the end of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach ensures that your model remains updated with recent data and can adapt to changing market conditions effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>momntm_30</th>\n",
       "      <th>momntm_60</th>\n",
       "      <th>momntm_90</th>\n",
       "      <th>momntm_120</th>\n",
       "      <th>momntm_180</th>\n",
       "      <th>momntm_270</th>\n",
       "      <th>momntm_300</th>\n",
       "      <th>momntm_360</th>\n",
       "      <th>drwdwn_15</th>\n",
       "      <th>drwdwn_60</th>\n",
       "      <th>drwdwn_90</th>\n",
       "      <th>drwdwn_120</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1929-06-11</th>\n",
       "      <td>25.430000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.650000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.070000</td>\n",
       "      <td>6.48</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>-0.035647</td>\n",
       "      <td>-0.035647</td>\n",
       "      <td>-0.035647</td>\n",
       "      <td>-0.035647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-06-12</th>\n",
       "      <td>25.450001</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.289999</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4.230001</td>\n",
       "      <td>5.010000</td>\n",
       "      <td>6.17</td>\n",
       "      <td>7.730001</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>-0.034888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-06-13</th>\n",
       "      <td>25.840000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.190001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.860001</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>5.450001</td>\n",
       "      <td>6.93</td>\n",
       "      <td>8.290001</td>\n",
       "      <td>-0.020099</td>\n",
       "      <td>-0.020099</td>\n",
       "      <td>-0.020099</td>\n",
       "      <td>-0.020099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-06-14</th>\n",
       "      <td>25.930000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0.290001</td>\n",
       "      <td>2.860001</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.880001</td>\n",
       "      <td>6.91</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>-0.016686</td>\n",
       "      <td>-0.016686</td>\n",
       "      <td>-0.016686</td>\n",
       "      <td>-0.016686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929-06-17</th>\n",
       "      <td>26.410000</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.709999</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.289999</td>\n",
       "      <td>7.42</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close  momntm_30  momntm_60  momntm_90  momntm_120  \\\n",
       "Date                                                                 \n",
       "1929-06-11  25.430000  -0.100000  -0.650000  -0.020000    2.990000   \n",
       "1929-06-12  25.450001  -0.490000  -0.590000  -0.289999    2.750000   \n",
       "1929-06-13  25.840000  -0.150000  -0.190001   0.000000    2.860001   \n",
       "1929-06-14  25.930000  -0.180000  -0.090000   0.290001    2.860001   \n",
       "1929-06-17  26.410000   0.039999   0.510000   0.709999    3.080000   \n",
       "\n",
       "            momntm_180  momntm_270  momntm_300  momntm_360  drwdwn_15  \\\n",
       "Date                                                                    \n",
       "1929-06-11    4.250000    5.070000        6.48    7.670000  -0.035647   \n",
       "1929-06-12    4.230001    5.010000        6.17    7.730001  -0.034888   \n",
       "1929-06-13    4.480000    5.450001        6.93    8.290001  -0.020099   \n",
       "1929-06-14    4.500000    5.880001        6.91    8.270000  -0.016686   \n",
       "1929-06-17    5.000000    6.289999        7.42    8.910000   0.000000   \n",
       "\n",
       "            drwdwn_60  drwdwn_90  drwdwn_120  \n",
       "Date                                          \n",
       "1929-06-11  -0.035647  -0.035647   -0.035647  \n",
       "1929-06-12  -0.034888  -0.034888   -0.034888  \n",
       "1929-06-13  -0.020099  -0.020099   -0.020099  \n",
       "1929-06-14  -0.016686  -0.016686   -0.016686  \n",
       "1929-06-17   0.000000   0.000000    0.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Momentum'] = (data['Adj Close'].pct_change(periods=252)*100).round(2)  # 252 days \n",
    "data.dropna(inplace=True)\n",
    "data = generate_signals(data, 1, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>momntm_30</th>\n",
       "      <th>momntm_60</th>\n",
       "      <th>momntm_90</th>\n",
       "      <th>momntm_120</th>\n",
       "      <th>momntm_180</th>\n",
       "      <th>momntm_270</th>\n",
       "      <th>momntm_300</th>\n",
       "      <th>momntm_360</th>\n",
       "      <th>drwdwn_15</th>\n",
       "      <th>drwdwn_60</th>\n",
       "      <th>drwdwn_90</th>\n",
       "      <th>drwdwn_120</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1930-06-16</th>\n",
       "      <td>20.559999</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-3.580000</td>\n",
       "      <td>-2.750000</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>-10.240000</td>\n",
       "      <td>-5.410000</td>\n",
       "      <td>-4.740000</td>\n",
       "      <td>-3.690001</td>\n",
       "      <td>-0.354677</td>\n",
       "      <td>-0.354677</td>\n",
       "      <td>-0.354677</td>\n",
       "      <td>-0.354677</td>\n",
       "      <td>-19.21</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930-06-17</th>\n",
       "      <td>20.580000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>-3.710001</td>\n",
       "      <td>-2.480000</td>\n",
       "      <td>0.190001</td>\n",
       "      <td>-10.270000</td>\n",
       "      <td>-5.510000</td>\n",
       "      <td>-4.469999</td>\n",
       "      <td>-3.590000</td>\n",
       "      <td>-0.354049</td>\n",
       "      <td>-0.354049</td>\n",
       "      <td>-0.354049</td>\n",
       "      <td>-0.354049</td>\n",
       "      <td>-20.36</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930-06-18</th>\n",
       "      <td>19.860001</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-4.420000</td>\n",
       "      <td>-3.109999</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>-11.269999</td>\n",
       "      <td>-5.529999</td>\n",
       "      <td>-4.969999</td>\n",
       "      <td>-4.680000</td>\n",
       "      <td>-0.376648</td>\n",
       "      <td>-0.376648</td>\n",
       "      <td>-0.376648</td>\n",
       "      <td>-0.376648</td>\n",
       "      <td>-23.41</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930-06-19</th>\n",
       "      <td>20.790001</td>\n",
       "      <td>-2.519999</td>\n",
       "      <td>-3.459999</td>\n",
       "      <td>-2.330000</td>\n",
       "      <td>-0.029999</td>\n",
       "      <td>-9.480000</td>\n",
       "      <td>-4.910000</td>\n",
       "      <td>-3.839998</td>\n",
       "      <td>-3.789999</td>\n",
       "      <td>-0.347458</td>\n",
       "      <td>-0.347458</td>\n",
       "      <td>-0.347458</td>\n",
       "      <td>-0.347458</td>\n",
       "      <td>-21.28</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930-06-20</th>\n",
       "      <td>20.250000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-4.370001</td>\n",
       "      <td>-3.070000</td>\n",
       "      <td>-0.639999</td>\n",
       "      <td>-9.910000</td>\n",
       "      <td>-4.510000</td>\n",
       "      <td>-4.530001</td>\n",
       "      <td>-4.290001</td>\n",
       "      <td>-0.364407</td>\n",
       "      <td>-0.364407</td>\n",
       "      <td>-0.364407</td>\n",
       "      <td>-0.364407</td>\n",
       "      <td>-23.35</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close  momntm_30  momntm_60  momntm_90  momntm_120  \\\n",
       "Date                                                                 \n",
       "1930-06-16  20.559999  -3.010000  -3.580000  -2.750000    0.299999   \n",
       "1930-06-17  20.580000  -2.400000  -3.710001  -2.480000    0.190001   \n",
       "1930-06-18  19.860001  -3.900000  -4.420000  -3.109999   -0.980000   \n",
       "1930-06-19  20.790001  -2.519999  -3.459999  -2.330000   -0.029999   \n",
       "1930-06-20  20.250000  -3.150000  -4.370001  -3.070000   -0.639999   \n",
       "\n",
       "            momntm_180  momntm_270  momntm_300  momntm_360  drwdwn_15  \\\n",
       "Date                                                                    \n",
       "1930-06-16  -10.240000   -5.410000   -4.740000   -3.690001  -0.354677   \n",
       "1930-06-17  -10.270000   -5.510000   -4.469999   -3.590000  -0.354049   \n",
       "1930-06-18  -11.269999   -5.529999   -4.969999   -4.680000  -0.376648   \n",
       "1930-06-19   -9.480000   -4.910000   -3.839998   -3.789999  -0.347458   \n",
       "1930-06-20   -9.910000   -4.510000   -4.530001   -4.290001  -0.364407   \n",
       "\n",
       "            drwdwn_60  drwdwn_90  drwdwn_120  Momentum  Signal  \n",
       "Date                                                            \n",
       "1930-06-16  -0.354677  -0.354677   -0.354677    -19.21      -1  \n",
       "1930-06-17  -0.354049  -0.354049   -0.354049    -20.36      -1  \n",
       "1930-06-18  -0.376648  -0.376648   -0.376648    -23.41      -1  \n",
       "1930-06-19  -0.347458  -0.347458   -0.347458    -21.28      -1  \n",
       "1930-06-20  -0.364407  -0.364407   -0.364407    -23.35      -1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Signal']!=0] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Signal\n",
       " 1    13203\n",
       "-1     9027\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Signal'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy:\n",
    "    def __init__(self):\n",
    "        self.conv_interval = 50  # days\n",
    "        self.retrain_freq = 252*8   # 8 years = 8*252 days\n",
    "        self.tolerance = 0.0001\n",
    "\n",
    "    def scaling_x(self, X):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_x = scaler.fit_transform(X)\n",
    "        return scaled_x \n",
    "\n",
    "    def cost_funcn(self, model, X, Y):\n",
    "        y_prob = model.predict_proba(X)[:,1]     # Getting probabilities for class 1 (positive class)\n",
    "        cost = log_loss(Y, y_prob) \n",
    "        return cost     \n",
    "    \n",
    "    def data_concat(self, y_pred, start, end, df):\n",
    "\n",
    "        datac = df[start:end] \n",
    "        y_pred = pd.Series(y_pred,index=datac.index) \n",
    "\n",
    "        bnch_df = datac[datac['Signal'] == 1].copy() \n",
    "        print('='*20,'Metric for bnch_df','='*20) \n",
    "        calc_kpi = KPIs(bnch_df)  \n",
    "        calc_kpi.calculate_kpi() \n",
    "\n",
    "        log_indices = y_pred[y_pred==1].index \n",
    "        log_df = df.loc[log_indices].copy()  # Filter original DataFrame based on indices\n",
    "        log_df['y_pred'] = y_pred[log_indices]     # Add y_pred column \n",
    "        log_df = log_df[['y_pred', 'Signal', 'Adj Close']] \n",
    "        # print(log_df.head(3))    \n",
    "        print('='*20,'Metric for log_df','='*20) \n",
    "        calc_kpi = KPIs(log_df)  \n",
    "        calc_kpi.calculate_kpi()\n",
    "        \n",
    "    def model_metrics(self, model, X, Y, start, end, df):\n",
    "        y_pred = model.predict(X) \n",
    "        cost_fn = self.cost_funcn(model, X, Y)\n",
    "        accuracy = accuracy_score(Y, y_pred)\n",
    "        conf_matrix = confusion_matrix(Y, y_pred)\n",
    "        class_report = classification_report(Y, y_pred)  \n",
    "        \n",
    "        print(f'Cost Function : {cost_fn}')\n",
    "        print(f'Accuracy Score : {accuracy}')\n",
    "        print('Confusion Matrix :') \n",
    "        print(conf_matrix) \n",
    "        print('Classification Report : ')\n",
    "        print(class_report) \n",
    "        \n",
    "        self.data_concat(y_pred, start, end, df)\n",
    "    \n",
    "    def date_correction(self,indx,df,num):\n",
    "        idx1 = df.index.get_loc(indx)\n",
    "        idx2 = idx1 + num \n",
    "        if idx2<len(df)-1:\n",
    "            return idx2 \n",
    "        else:\n",
    "            return len(df)-1   \n",
    "    \n",
    "    def training_logistic(self, df):\n",
    "        models = []     \n",
    "        # Initialize Parameters        \n",
    "        train_start = df.index[0]\n",
    "        train_end = df.index[int(0.4*len(df))] \n",
    "        test_start = train_end \n",
    "        idx = df.index.get_loc(test_start)+252*8 \n",
    "        test_end = df.index[idx] \n",
    "\n",
    "        model = LogisticRegression() \n",
    "\n",
    "        # Initial Training set\n",
    "        x_train = df.loc[train_start:train_end].drop('Signal', axis=1) \n",
    "        xs_train = self.scaling_x(x_train) \n",
    "        y_train = df.loc[train_start:train_end, 'Signal'] \n",
    "\n",
    "        x_test = df.loc[test_start:test_end].drop('Signal', axis=1) \n",
    "        xs_test = self.scaling_x(x_test) \n",
    "        y_test = df.loc[test_start:test_end, 'Signal'] \n",
    "\n",
    "        model.fit(xs_train, y_train)\n",
    "\n",
    "        print(f'Train set interval: {str(train_start).split(' 00:00:00')[0]} to {str(train_end).split(' 00:00:00')[0]}')       \n",
    "        print() \n",
    "        print('='*20,'Metrics','='*20) \n",
    "        self.model_metrics(model, xs_train, y_train, train_start, train_end, df)\n",
    "\n",
    "        print(f'Test set interval: {str(test_start).split(' 00:00:00')[0]} to {str(test_end).split(' 00:00:00')[0]}')       \n",
    "        print()\n",
    "        print('='*20,'Metrics','='*20) \n",
    "        self.model_metrics(model, xs_test, y_test, test_start, test_end, df)\n",
    "         \n",
    "\n",
    "        # Training Loop  \n",
    "        while test_end<df.index[-1]:\n",
    "\n",
    "            model.fit(xs_train, y_train)\n",
    "\n",
    "            # Loop for checking convergence\n",
    "            previous_cost = None \n",
    "\n",
    "            while test_end<df.index[-1]:\n",
    "                x_test = df.loc[test_start:test_end].drop('Signal', axis=1) \n",
    "                xs_test = self.scaling_x(x_test) \n",
    "                y_test = df.loc[test_start:test_end, 'Signal'] \n",
    "                            \n",
    "                current_cost = self.cost_funcn(model,xs_test,y_test) \n",
    "\n",
    "                if previous_cost is not None and (previous_cost-current_cost)/previous_cost < self.tolerance:\n",
    "                    print() \n",
    "                    print(f'Convergence achieved at {str(test_end).split(' 00:00:00')[0]}') \n",
    "                    break   \n",
    "                \n",
    "                previous_cost = current_cost\n",
    "                idx = self.date_correction(test_end,df,self.conv_interval)  \n",
    "                test_end = df.index[idx] \n",
    "\n",
    "            # Slide the training window \n",
    "            idxt1 = self.date_correction(train_start, df,self.retrain_freq)\n",
    "            train_start = df.index[idxt1] \n",
    "\n",
    "            idxt2 = self.date_correction(train_end, df,self.retrain_freq)\n",
    "            train_end = df.index[idxt2]\n",
    "\n",
    "            test_start = train_end \n",
    "\n",
    "            idxs = self.date_correction(test_end, df,self.retrain_freq)\n",
    "            test_end = df.index[idxs]  \n",
    "\n",
    "            # Updating training data\n",
    "            \n",
    "            if train_end<=df.index[-1]:\n",
    "                x_train = df.loc[train_start:train_end].drop('Signal', axis=1) \n",
    "                xs_train = self.scaling_x(x_train) \n",
    "                y_train = df.loc[train_start:train_end, 'Signal'] \n",
    "\n",
    "            print(f'Train set interval: {str(train_start).split(' 00:00:00')[0]} to {str(train_end).split(' 00:00:00')[0]}')       \n",
    "            print()\n",
    "            print('='*20,'Metrics','='*20) \n",
    "            model_m = model.fit(xs_train,y_train) \n",
    "            models.append(model_m) \n",
    "            self.model_metrics(model_m, xs_train, y_train, train_start, train_end, df)   \n",
    "\n",
    "            # Updating Testing data\n",
    "            \n",
    "            if test_end not in list(df.index):\n",
    "                print(type(test_end))\n",
    "                print(test_end)\n",
    "                print(type(df.index[-1]))\n",
    "                print(df.index[-1]) \n",
    "                print(df.index)  \n",
    "                test_end = df.index[-1] \n",
    "                x_test = df.loc[test_start:test_end].drop('Signal', axis=1) \n",
    "                xs_test = self.scaling_x(x_test) \n",
    "                y_test = df.loc[test_start:test_end, 'Signal'] \n",
    "            else: \n",
    "                print(type(test_end))\n",
    "                print(type(df.index[-1])) \n",
    "                x_test = df.loc[test_start:test_end].drop('Signal', axis=1) \n",
    "                xs_test = self.scaling_x(x_test) \n",
    "                y_test = df.loc[test_start:test_end, 'Signal'] \n",
    "\n",
    "            print(f'Test set interval: {str(test_start).split(' 00:00:00')[0]} to {str(test_end).split(' 00:00:00')[0]}')       \n",
    "            print()\n",
    "            print('='*20,'Metrics','='*20) \n",
    "            self.model_metrics(model_m, xs_test, y_test, test_start, test_end, df)   \n",
    "            print('*'*100)\n",
    "        return models \n",
    "        \n",
    "strategy = Strategy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set interval: 1929-06-11 to 1964-12-15\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.029848665106413177\n",
      "Accuracy Score : 0.991453952546947\n",
      "Confusion Matrix :\n",
      "[[4220   26]\n",
      " [  50 4597]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      4246\n",
      "           1       0.99      0.99      0.99      4647\n",
      "\n",
      "    accuracy                           0.99      8893\n",
      "   macro avg       0.99      0.99      0.99      8893\n",
      "weighted avg       0.99      0.99      0.99      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 6.6%\n",
      "Sharpe Ratio : 0.25\n",
      "Volatility : 26%\n",
      "Maximum Drawdown : -78%\n",
      "Average Daily Drawdown : -31%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 6.7%\n",
      "Sharpe Ratio : 0.25\n",
      "Volatility : 25%\n",
      "Maximum Drawdown : -78%\n",
      "Average Daily Drawdown : -31%\n",
      "Test set interval: 1964-12-15 to 1973-01-23\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.19351941785372634\n",
      "Accuracy Score : 0.92563212692117\n",
      "Confusion Matrix :\n",
      "[[ 701  149]\n",
      " [   1 1166]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.82      0.90       850\n",
      "           1       0.89      1.00      0.94      1167\n",
      "\n",
      "    accuracy                           0.93      2017\n",
      "   macro avg       0.94      0.91      0.92      2017\n",
      "weighted avg       0.93      0.93      0.92      2017\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 7.9%\n",
      "Sharpe Ratio : 0.42\n",
      "Volatility : 11%\n",
      "Maximum Drawdown : -17%\n",
      "Average Daily Drawdown : -3%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 7.0%\n",
      "Sharpe Ratio : 0.42\n",
      "Volatility : 9%\n",
      "Maximum Drawdown : -17%\n",
      "Average Daily Drawdown : -4%\n",
      "\n",
      "Convergence achieved at 1973-06-18\n",
      "Train set interval: 1937-07-12 to 1973-01-23\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.0297355829038556\n",
      "Accuracy Score : 0.9922410884965703\n",
      "Confusion Matrix :\n",
      "[[3925   28]\n",
      " [  41 4899]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      3953\n",
      "           1       0.99      0.99      0.99      4940\n",
      "\n",
      "    accuracy                           0.99      8893\n",
      "   macro avg       0.99      0.99      0.99      8893\n",
      "weighted avg       0.99      0.99      0.99      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 10.6%\n",
      "Sharpe Ratio : 0.44\n",
      "Volatility : 15%\n",
      "Maximum Drawdown : -46%\n",
      "Average Daily Drawdown : -7%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 10.6%\n",
      "Sharpe Ratio : 0.45\n",
      "Volatility : 14%\n",
      "Maximum Drawdown : -46%\n",
      "Average Daily Drawdown : -7%\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Test set interval: 1973-01-23 to 1981-06-10\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.2781340806679358\n",
      "Accuracy Score : 0.9069437883797827\n",
      "Confusion Matrix :\n",
      "[[929 197]\n",
      " [  0 991]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.83      0.90      1126\n",
      "           1       0.83      1.00      0.91       991\n",
      "\n",
      "    accuracy                           0.91      2117\n",
      "   macro avg       0.92      0.91      0.91      2117\n",
      "weighted avg       0.92      0.91      0.91      2117\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 2.9%\n",
      "Sharpe Ratio : 0.13\n",
      "Volatility : 17%\n",
      "Maximum Drawdown : -30%\n",
      "Average Daily Drawdown : -11%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 2.4%\n",
      "Sharpe Ratio : 0.11\n",
      "Volatility : 15%\n",
      "Maximum Drawdown : -30%\n",
      "Average Daily Drawdown : -11%\n",
      "****************************************************************************************************\n",
      "\n",
      "Convergence achieved at 1981-10-30\n",
      "Train set interval: 1945-07-30 to 1981-01-16\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.02988252676236231\n",
      "Accuracy Score : 0.9923535364893736\n",
      "Confusion Matrix :\n",
      "[[3868   34]\n",
      " [  34 4957]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      3902\n",
      "           1       0.99      0.99      0.99      4991\n",
      "\n",
      "    accuracy                           0.99      8893\n",
      "   macro avg       0.99      0.99      0.99      8893\n",
      "weighted avg       0.99      0.99      0.99      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 11.9%\n",
      "Sharpe Ratio : 0.54\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -32%\n",
      "Average Daily Drawdown : -5%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 11.9%\n",
      "Sharpe Ratio : 0.55\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -32%\n",
      "Average Daily Drawdown : -5%\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Test set interval: 1981-01-16 to 1989-10-20\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.37193315604586064\n",
      "Accuracy Score : 0.9088858818222824\n",
      "Confusion Matrix :\n",
      "[[ 750    7]\n",
      " [ 195 1265]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.99      0.88       757\n",
      "           1       0.99      0.87      0.93      1460\n",
      "\n",
      "    accuracy                           0.91      2217\n",
      "   macro avg       0.89      0.93      0.90      2217\n",
      "weighted avg       0.93      0.91      0.91      2217\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 17.8%\n",
      "Sharpe Ratio : 0.68\n",
      "Volatility : 15%\n",
      "Maximum Drawdown : -23%\n",
      "Average Daily Drawdown : -4%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 20.6%\n",
      "Sharpe Ratio : 0.75\n",
      "Volatility : 16%\n",
      "Maximum Drawdown : -26%\n",
      "Average Daily Drawdown : -3%\n",
      "****************************************************************************************************\n",
      "\n",
      "Convergence achieved at 1990-01-03\n",
      "Train set interval: 1953-08-26 to 1989-01-06\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.026603473848338596\n",
      "Accuracy Score : 0.9948273923310469\n",
      "Confusion Matrix :\n",
      "[[3833   28]\n",
      " [  18 5014]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.99      0.99      3861\n",
      "           1       0.99      1.00      1.00      5032\n",
      "\n",
      "    accuracy                           0.99      8893\n",
      "   macro avg       0.99      0.99      0.99      8893\n",
      "weighted avg       0.99      0.99      0.99      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 12.5%\n",
      "Sharpe Ratio : 0.55\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -32%\n",
      "Average Daily Drawdown : -5%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 12.4%\n",
      "Sharpe Ratio : 0.56\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -32%\n",
      "Average Daily Drawdown : -5%\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Test set interval: 1989-01-06 to 1997-12-22\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 2.4538634149954963\n",
      "Accuracy Score : 0.6678429642699603\n",
      "Confusion Matrix :\n",
      "[[ 447    0]\n",
      " [ 753 1067]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54       447\n",
      "           1       1.00      0.59      0.74      1820\n",
      "\n",
      "    accuracy                           0.67      2267\n",
      "   macro avg       0.69      0.79      0.64      2267\n",
      "weighted avg       0.88      0.67      0.70      2267\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 18.5%\n",
      "Sharpe Ratio : 0.84\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -11%\n",
      "Average Daily Drawdown : -2%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 31.7%\n",
      "Sharpe Ratio : 1.06\n",
      "Volatility : 17%\n",
      "Maximum Drawdown : -11%\n",
      "Average Daily Drawdown : -2%\n",
      "****************************************************************************************************\n",
      "\n",
      "Convergence achieved at 1998-03-06\n",
      "Train set interval: 1961-08-30 to 1996-12-26\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.028159405077162962\n",
      "Accuracy Score : 0.9951647363094569\n",
      "Confusion Matrix :\n",
      "[[3416   32]\n",
      " [  11 5434]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.99      0.99      3448\n",
      "           1       0.99      1.00      1.00      5445\n",
      "\n",
      "    accuracy                           1.00      8893\n",
      "   macro avg       1.00      0.99      0.99      8893\n",
      "weighted avg       1.00      1.00      1.00      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 11.8%\n",
      "Sharpe Ratio : 0.53\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -32%\n",
      "Average Daily Drawdown : -5%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 11.8%\n",
      "Sharpe Ratio : 0.54\n",
      "Volatility : 13%\n",
      "Maximum Drawdown : -32%\n",
      "Average Daily Drawdown : -5%\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Test set interval: 1996-12-26 to 2006-03-13\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.08188274947215397\n",
      "Accuracy Score : 0.9620198532585239\n",
      "Confusion Matrix :\n",
      "[[ 687   83]\n",
      " [   5 1542]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.89      0.94       770\n",
      "           1       0.95      1.00      0.97      1547\n",
      "\n",
      "    accuracy                           0.96      2317\n",
      "   macro avg       0.97      0.94      0.96      2317\n",
      "weighted avg       0.96      0.96      0.96      2317\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 9.0%\n",
      "Sharpe Ratio : 0.31\n",
      "Volatility : 21%\n",
      "Maximum Drawdown : -37%\n",
      "Average Daily Drawdown : -12%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 8.6%\n",
      "Sharpe Ratio : 0.30\n",
      "Volatility : 20%\n",
      "Maximum Drawdown : -37%\n",
      "Average Daily Drawdown : -12%\n",
      "****************************************************************************************************\n",
      "\n",
      "Convergence achieved at 2006-08-03\n",
      "Train set interval: 1969-10-14 to 2004-12-31\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.026232189546709993\n",
      "Accuracy Score : 0.9966265602159001\n",
      "Confusion Matrix :\n",
      "[[3337   26]\n",
      " [   4 5526]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.99      1.00      3363\n",
      "           1       1.00      1.00      1.00      5530\n",
      "\n",
      "    accuracy                           1.00      8893\n",
      "   macro avg       1.00      1.00      1.00      8893\n",
      "weighted avg       1.00      1.00      1.00      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 12.3%\n",
      "Sharpe Ratio : 0.47\n",
      "Volatility : 16%\n",
      "Maximum Drawdown : -37%\n",
      "Average Daily Drawdown : -6%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 12.3%\n",
      "Sharpe Ratio : 0.47\n",
      "Volatility : 16%\n",
      "Maximum Drawdown : -37%\n",
      "Average Daily Drawdown : -6%\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Test set interval: 2004-12-31 to 2014-08-07\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.3087555659474664\n",
      "Accuracy Score : 0.90235829540753\n",
      "Confusion Matrix :\n",
      "[[ 543  236]\n",
      " [   0 1638]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.70      0.82       779\n",
      "           1       0.87      1.00      0.93      1638\n",
      "\n",
      "    accuracy                           0.90      2417\n",
      "   macro avg       0.94      0.85      0.88      2417\n",
      "weighted avg       0.91      0.90      0.90      2417\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 7.2%\n",
      "Sharpe Ratio : 0.27\n",
      "Volatility : 18%\n",
      "Maximum Drawdown : -35%\n",
      "Average Daily Drawdown : -9%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 6.3%\n",
      "Sharpe Ratio : 0.25\n",
      "Volatility : 17%\n",
      "Maximum Drawdown : -35%\n",
      "Average Daily Drawdown : -9%\n",
      "****************************************************************************************************\n",
      "\n",
      "Convergence achieved at 2015-10-15\n",
      "Train set interval: 1977-10-06 to 2013-01-04\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 0.034131672707404984\n",
      "Accuracy Score : 0.9941527043742269\n",
      "Confusion Matrix :\n",
      "[[3006   44]\n",
      " [   8 5835]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.99      0.99      3050\n",
      "           1       0.99      1.00      1.00      5843\n",
      "\n",
      "    accuracy                           0.99      8893\n",
      "   macro avg       0.99      0.99      0.99      8893\n",
      "weighted avg       0.99      0.99      0.99      8893\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 12.1%\n",
      "Sharpe Ratio : 0.44\n",
      "Volatility : 17%\n",
      "Maximum Drawdown : -37%\n",
      "Average Daily Drawdown : -8%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 12.0%\n",
      "Sharpe Ratio : 0.44\n",
      "Volatility : 17%\n",
      "Maximum Drawdown : -37%\n",
      "Average Daily Drawdown : -8%\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "Test set interval: 2013-01-04 to 2017-12-08\n",
      "\n",
      "==================== Metrics ====================\n",
      "Cost Function : 2.173721978876343\n",
      "Accuracy Score : 0.7481898632341111\n",
      "Confusion Matrix :\n",
      "[[263   0]\n",
      " [313 667]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      1.00      0.63       263\n",
      "           1       1.00      0.68      0.81       980\n",
      "\n",
      "    accuracy                           0.75      1243\n",
      "   macro avg       0.73      0.84      0.72      1243\n",
      "weighted avg       0.89      0.75      0.77      1243\n",
      "\n",
      "==================== Metric for bnch_df ====================\n",
      "Annual Return : 16.5%\n",
      "Sharpe Ratio : 0.87\n",
      "Volatility : 11%\n",
      "Maximum Drawdown : -7%\n",
      "Average Daily Drawdown : -1%\n",
      "==================== Metric for log_df ====================\n",
      "Annual Return : 24.9%\n",
      "Sharpe Ratio : 1.48\n",
      "Volatility : 9%\n",
      "Maximum Drawdown : -5%\n",
      "Average Daily Drawdown : -1%\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "models = strategy.training_logistic(x_cubic)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(),\n",
       " LogisticRegression(),\n",
       " LogisticRegression(),\n",
       " LogisticRegression(),\n",
       " LogisticRegression(),\n",
       " LogisticRegression()]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Calculating Key Performance Indicators of various Logistic regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1 Benchmark SPX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 Logistic Regression Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.3 Logistic Regression Quadratic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.4 Logistic Regression Cubic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Retraining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps:\n",
    "\n",
    "Frequency at which training set should be revised on regular intervals as new data is generated in market\n",
    "\n",
    "1. Retraining period is about 5 and 10 years for one asset\n",
    "2. But for a portfolio with multiple assets, this approach is not feasible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
